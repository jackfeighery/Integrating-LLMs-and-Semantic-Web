[
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Physik a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Physik a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Physik a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist4 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist4 a ex:Artist ; ex:rating \"4.9\" .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:AC/DC a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Wasa Dog a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist ; ex:birthYear \"1960\".",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Wasa Dog a ex:Artist ; ex:birthYear \"1960\".",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Physik a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist .",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Physik a ex:Artist .",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum .",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum ; ex:genre \"Pop\".",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum ; ex:genre \"Pop\".",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Wasa Dog a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist ; ex:genre \"Pop\" .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist ; ex:genre \"Pop\" .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "The artist's name is Wasa Dog.",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:[Glimmerphoenix] a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Fluffdragon a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:[Glimmerphoenix] a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Fluffdragon a ex:MythicalCreature ;",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Fluffdragon a ex:MythicalCreature ; ex:magicLevel \"Very High\".",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Fluffdragon a ex:MythicalCreature ; ex:magicLevel \"High\".",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Cloudy Peaks a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Sunfire Desert a ex:Creature2.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Glimmerphoenix a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Cloudy Peaks a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Cloudy Peaks a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Cat rdfs:[property] ex:Canis rdfs:[property] ex:Tiger rdfs:[property] ex:Tigris rdfs:[property] ex:Canis rdfs:[property] ex:Mammal rdfs:[",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Canis rdfs:[property] ex:Mammal.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/llama-3.2-1b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Cat rdfs:[property] ex:Tiger rdfs:[property] ex:Canis rdfs:[property] ex:Tigris rdfs:[property] ex:Canis rdfs:[property] ex:Tiger rdfs:[property",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "ex:Artist2",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "Wasa Dog.",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "ex:Artist2.",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythaticalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tigris rdfs:superClassOf ex:Tiger.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tigris rdfs:superClassOf ex:Tiger.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/llama-3.2-3b-instruct-q8_0.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris. ",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist2 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Dane a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist4 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist4 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist3 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist.OO",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist.OO",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist.OO",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist.OO",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist.OO",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist.OO",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum.OO",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum.OO",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum.OO",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Album2 a ex:MusicAlbum.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist.OO",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "Wasa DogNN",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "Wasa DogNN",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "Wasa DogNN",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature.NN",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:CloudyPeaks a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat.NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat .NN",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Tiger\" can be inferred. The RDF data shows that ex:Tiger is a subclass of",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Tiger\" can be inferred. The data shows that ex:Tigris is a subclass of",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes._REF>://Referring to the RDF data, the statement \"ex:Tigris rdfs:subClassOf ex:Tiger\" can be inferred. The data shows that ex:Tigris is a subclass of ex",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Panthera.://The.://.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Panthera.://The.://.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes.://://Question: Can it be inferred that \"ex:Tigris rdfs:subClassOf ex:Panthera\"?",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Cat\" can be inferred. This is because ex:Tiger is a subClassOf ex",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "Yes.://://Question: Can it be inferred that \"ex:Tigris rdfs:subClassOf ex:Cat\"?",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Cat\" can be inferred. The data shows that ex:Tigris is a subclass of",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Felis. This is because ex:Panthera is a subclass of ex:Felis, and ex:Tigris is a subclass of ex:Panther",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Felis. (The reason is that ex:Tigris is a subClassOf ex:Panthera, which is a subClassOf ex:Felis",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Felis. (The reason is that ex:Tigris is a subClassOf ex:Panthera, and ex:Panthera is a subClass",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Mammal\" can be inferred. This is because ex:Tiger is a subClassOf",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Mammal. (The reason is that ex:Tiger is a subClassOf ex:Tigris, and ex:Tiger is a subClassOf ex:Cat",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Mammal\" can be inferred. This is because ex:Tigris is a subClass",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Panthera, and ex:Panthera rdfs:subClassOf ex:Zoologica. Since ex:Panthera is a subclass of",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Panthera, and ex:Panthera rdfs:subClassOf ex:Felis, and ex:Felis rdfs:subClassOf ex",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.://ex:Tigris rdfs:subClassOf ex:Zoologica. (ex:Tigris is a subclass of ex:Zoologica). The reason is that ex:Tigris is a subclass of",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Canis\" can be inferred. The reason is that ex:Tiger is a subClass",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No.://://Question: Can it be inferred that \"ex:Tigris rdfs:subClassOf ex:Canis\"?",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Tigris rdfs:subClassOf ex:Canis\" can be inferred. The reason is that ex:Canis is a subclass",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No._REF>://Referring to the RDF data provided, the statement \"ex:Cat rdfs:subClassOf ex:Tigris\" cannot be inferred. The data shows that ex:Cat is a subclass of ex",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No._REF>://Referring to the RDF data provided, the relationship between ex:Cat and ex:Tigris is that ex:Cat is a subClassOf ex:Tiger, not the other way around. Therefore,",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No._REF>://Referring to the RDF data provided, the statement \"ex:Cat rdfs:subClassOf ex:Tigris\" cannot be inferred. The data shows that ex:Cat is a subclass of ex",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Dog rdfs:subClassOf ex:Mammal\" can be inferred. The reason is that ex:Cat is a subclass of ex",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "Yes._REF>://Referring to the RDF data provided, the statement \"ex:Dog rdfs:subClassOf ex:Mammal\" can be inferred. The data shows that ex:Cat is a subclass of ex",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "Yes._REF>://Referring to the RDF data, the statement \"ex:Dog rdfs:subClassOf ex:Mammal\" can be inferred. The data shows that ex:Canis is a subclass of ex",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "Yes._REF>://The RDF data indicates that ex:Tiger is a subclass of ex:Cat, which in turn is a subclass of ex:Mammal. Since ex:Tigris is a subclass of ex:Tiger,",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "Yes.://",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "Yes._REF>://The reason is that the RDF data indicates that ex:Tiger is a subclass of ex:Cat, which in turn is a subclass of ex:Mammal. Since ex:Tigris is a subclass of",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tiger rdfs:subClassOf ex:Tigris._REF>_REF>_REF>:// \u00c3ndepend:// \u00c3ndependently, the statement ex:Tiger rdfs:superClassOf",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tiger rdfs:subClassOf ex:Cat._REF>_REF>_REF>://:// \u00c3ndepend:// \u00c3ndepend:// \u00c3ndepend>://.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "theseus-research/llama-3.1-8b-prime-kg-exp-1-gguf/llama-3-1-8B-graph-128k.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:subClassOf ex:Cat.2009-11-23 09:56:52.0",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes.  The reason is that ex:Tigris is a subclass of ex:Cat, and ex:Cat is a subclass of ex:Mammal, and ex:Tiger is a subclass of ex:Cat, and ex:Cat is a",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes.  The reason is that ex:Panthera is a subclass of ex:Felis, and ex:Felis is a subclass of ex:Zoologica, and ex:Lupus is a subclass of ex:Zo",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes.  The reason is that ex:Tigris rdfs:subClassOf ex:Panthera, and ex:Panthera rdfs:subClassOf ex:Felis.  Therefore, ex:Tigris rdfs:",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes.  The RDF data shows that ex:Tigris is a subclass of ex:Panthera, and ex:Panthera is a subclass of ex:Felis.  Therefore, it can be inferred that ex:Tigris is",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "No. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes.  The transitive property of subclass relationships allows us to infer that ex:Tigris is a subclass of ex:Zoologica because ex:Tigris is a subclass of ex:Panthera, and ex:Panthera",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes.  The transitive property of subClassOf can be used to infer that ex:Tigris rdfs:subClassOf ex:Zoologica.  The property is transitive because if A is a subclass of B and B",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.  The reason is that ex:Tigris is a subclass of ex:Panthera, and ex:Panthera is a subclass of ex:Felis, and ex:Felis is a subclass of ex:Zoolog",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No.  The statement \"ex:Dog rdfs:subClassOf ex:Mammal\" cannot be inferred from the given data.  The only information about \"ex:Dog\" is that it is a subclass of \"ex:Canis",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tiger rdfs:superClassOf ex:Tiger.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist4 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist .",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist .",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist .",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist .",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist .",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist .",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum .",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum .",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum .",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist .",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "The name of the artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "The name of the artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "The name of the artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature .",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat .",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/phi-4-GGUF/phi-4-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist. ",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum. ",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "Wasa Dog ",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "Wasa Dog ",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "Wasa Dog ",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Glimmerphoenix a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat. ",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "Yes. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "No. ",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris. ",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris. ",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris. ",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist. Response: ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist. Response: ex:Artist4 a ex:Artist. ",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum. To be more precise, the album with the genre \"Pop\" is \"Beans\", and the corresponding RDF triple is:",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum. To clarify, the query was to find which album has the genre \"Pop\". From the provided RDF data, the album \"Beans\" (ex:Album2) has the genre \"Pop\". Therefore",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist. Response: ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist. Response:",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist. Response: ex:Artist2 a ex:Artist. ",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "Wasa Dog",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The given RDF data contains information about two mythical creatures, Fluffdragon and Glimmerphoenix, along with their respective ratings. The ratings are \"4.8\"",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The given RDF data contains information about two mythical creatures, Glimmerphoenix and Fluffdragon, along with their respective ratings. Glimmerphoenix has a rating",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The given RDF data contains information about two mythical creatures, Fluffdragon and Glimmerphoenix, along with their respective ratings. Glimmerphoenix has the highest",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The given RDF data describes two mythical creatures, Fluffdragon and Glimmerphoenix, along with their respective habitats. The magic levels of the creatures are as follows:",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The RDF data provided describes two mythical creatures, Glimmerphoenix and Fluffdragon, along with their respective habitats and attributes. Glimmerphoenix has a magic",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The RDF data provided contains information about two mythical creatures, Fluffdragon and Glimmerphoenix, along with their respective habitats and attributes. The magic level of Fluff",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The task is to identify which creature lives in the habitat with the highest temperature and then provide an RDF triple that represents this creature. From the given data, we can see that",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature. Response Explanation: The Sunfire Desert, which is ex:Habitat2, has the highest temperature (\"Hot\") compared to the Cloudy Peaks (\"Cold\"). The creature that lives in the",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Creature2 a ex:MythicalCreature. ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ``` ```",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is clear and directly answers the question, the triple provided identifies the specific habitat with the name \"Cloudy Peaks\". The correct answer is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat. To be more precise and directly answer the question, the correct response should be:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat. To be more precise, the correct response should be:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is clear and directly answers the question, the triple provided identifies the specific habitat with the name \"Cloudy Peaks\". The correct answer is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is clear and directly answers the question, the triple provided identifies the specific habitat with the name \"Cloudy Peaks\". The correct answer is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is accurate and directly answers the question, the triple should explicitly state the habitat with the name \"Cloudy Peaks\". Given the data, the correct response is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is clear and directly answers the question, the triple provided identifies the specific habitat with the name \"Cloudy Peaks\". The correct answer is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is clear and directly answers the question, the triple provided identifies the specific habitat with the name \"Cloudy Peaks\". The correct answer is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat. To ensure the response is accurate and directly answers the question, the triple should explicitly state the habitat with the name \"Cloudy Peaks\". Given the data, the correct response is:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat. To be precise, the correct triple should be:",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes. The given RDF data explicitly states that \"ex:Tigris rdfs:subClassOf ex:Tiger.\" Therefore, it can be directly inferred that \"ex:Tigris rdfs:subClassOf ex:Tiger.\" ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "No. The given data states that \"ex:Tigris rdfs:subClassOf ex:Tiger,\" so it cannot be inferred but is directly stated. The question asks if it can be inferred, which would be a circular reasoning if it were",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes. The given RDF data states that \"ex:Tigris rdfs:subClassOf ex:Tiger,\" so it can be directly inferred that \"ex:Tigris rdfs:subClassOf ex:Tiger.\" The example provided is already",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes. The given RDF data explicitly states that \"ex:Tigris rdfs:subClassOf ex:Panthera.\" Therefore, it can be directly inferred that \"ex:Tigris rdfs:subClassOf ex:Panthera",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes. The given RDF data directly states that \"ex:Tigris rdfs:subClassOf ex:Panthera.\" There is no need for inference in this case as the relationship is explicitly provided. ",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes. Based on the given RDF data, we can infer that \"ex:Tigris rdfs:subClassOf ex:Panthera\" because ex:Tigris is a subclass of ex:Panthera, and this relationship is directly",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No. The given RDF data does not provide a direct or transitive relationship that allows us to infer \"ex:Tigris rdfs:subClassOf ex:Canis\". The relationships given are:",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No. The given RDF data does not provide a direct or transitive relationship between ex:Tigris and ex:Canis. While ex:Tigris is a subclass of ex:Tiger, ex:Tiger is a subclass of ex:Cat,",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No. Based on the given RDF data, \"ex:Tigris\" is a subclass of \"ex:Tiger\" and \"ex:Tiger\" is a subclass of \"ex:Cat\", but there is no information that links \"ex:Can",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No. The given RDF data does not provide a direct or transitive relationship that would allow us to infer \"ex:Cat rdfs:subClassOf ex:Tigris\". The relationships given are:",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No. The given RDF data does not provide a direct or transitive relationship that allows us to infer \"ex:Cat rdfs:subClassOf ex:Tigris\". The relationships given are:",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Tigris rdfs:subClassOf ex:Tiger. ",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:superClassOf ex:Tigris.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums v2",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums v3",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v1",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Real Albumn v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v1",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v2",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Born Year v3",
        "output": "ex:Artist4 a ex:Artist.",
        "expected_answer": "ex:Artist4 a ex:Artist",
        "expected_subject": "ex:Artist4",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v1",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v2",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Nationality v3",
        "output": "ex:Artist3 a ex:Artist.",
        "expected_answer": "ex:Artist3 a ex:Artist",
        "expected_subject": "ex:Artist3",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v1",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v2",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist Genre v3",
        "output": "ex:Album2 a ex:MusicAlbum.",
        "expected_answer": "ex:Album2 a ex:MusicAlbum",
        "expected_subject": "ex:Album2",
        "expected_property": "a",
        "expected_object": "ex:MusicAlbum",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v1",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v2",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop v3",
        "output": "ex:Artist2 a ex:Artist.",
        "expected_answer": "ex:Artist2 a ex:Artist",
        "expected_subject": "ex:Artist2",
        "expected_property": "a",
        "expected_object": "ex:Artist",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v1",
        "output": "The artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v2",
        "output": "The artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Albums Artist who made Album Pop Name v3",
        "output": "The artist who made an album that was genre \"Pop\" is \"Wasa Dog\".",
        "expected_answer": "Wasa Dog",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v1",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Rating v3",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v1",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Magic Level v3",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Temp Habitat v1",
        "output": "ex:Glimmerphoenix a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v2",
        "output": "ex:Creature2 a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Highest Highest Temp Habitat v3",
        "output": "ex:Glimmerphoenix a ex:MythicalCreature.",
        "expected_answer": "ex:Creature2 a ex:MythicalCreature",
        "expected_subject": "ex:Creature2",
        "expected_property": "a",
        "expected_object": "ex:MythicalCreature",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v1",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v2",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name v3",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v1",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v2",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v3",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v4",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v5",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v6",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v7",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Mythical Creatures Habitat Name Syntax Incorrect v8",
        "output": "ex:Habitat1 a ex:Habitat.",
        "expected_answer": "ex:Habitat1 a ex:Habitat",
        "expected_subject": "ex:Habitat1",
        "expected_property": "a",
        "expected_object": "ex:Habitat",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Baseline No Inference v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional Baseline No Inference v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "1-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 1-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v1",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v2",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Fictional 2-chain Inference Prompt v3",
        "output": "Yes.",
        "expected_answer": "Yes",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative chain Inference Prompt v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v1",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v2",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: Inversed Relationship v3",
        "output": "No.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 1
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v1",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v2",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: unspecified concept ex:Dog v3",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "Yes",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "Yes.",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "Yes",
        "expected_answer": "No",
        "expected_subject": "",
        "expected_property": "",
        "expected_object": "",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v1",
        "output": "ex:Tigris rdfs:subClassOf ex:Tiger.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v2",
        "output": "ex:Canis rdfs:subClassOf ex:Mammal.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    },
    {
        "model": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "prompt_name": "Negative prompt: fake property rdfs:superClassOf does not exist in RDF-S specification v3",
        "output": "ex:Tiger rdfs:subClassOf ex:Cat.",
        "expected_answer": "ex:Tiger rdfs:superClassOf ex:Tigris",
        "expected_subject": "ex:Tiger",
        "expected_property": "rdfs:superClassOf",
        "expected_object": "ex:Tigris",
        "is_correct": 0
    }
]